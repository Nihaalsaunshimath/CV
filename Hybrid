import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
import matplotlib.pyplot as plt

# Device Configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Retinex Decomposition Module
class RetinexDecomposition(nn.Module):
    def _init_(self):
        super(RetinexDecomposition, self)._init_()
        self.illumination_net = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(16, 3, kernel_size=3, stride=1, padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        illumination = self.illumination_net(x)
        reflectance = x / (illumination + 1e-6)  # Avoid division by zero
        return illumination, reflectance

# U-Net Enhancement Module
class UNetEnhancement(nn.Module):
    def _init_(self):
        super(UNetEnhancement, self)._init_()
        self.enc1 = self.contract_block(3, 64)
        self.enc2 = self.contract_block(64, 128)
        self.enc3 = self.contract_block(128, 256)
        self.enc4 = self.contract_block(256, 512)
        self.bottleneck = self.contract_block(512, 1024)
        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.dec4 = self.expand_block(1024, 512)
        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.dec3 = self.expand_block(512, 256)
        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dec2 = self.expand_block(256, 128)
        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.dec1 = self.expand_block(128, 64)
        self.final = nn.Conv2d(64, 3, kernel_size=1, stride=1)

    def contract_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )

    def expand_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.ReLU()
        )

    def forward(self, x):
        enc1 = self.enc1(x)
        enc2 = self.enc2(enc1)
        enc3 = self.enc3(enc2)
        enc4 = self.enc4(enc3)
        bottleneck = self.bottleneck(enc4)
        up4 = self.upconv4(bottleneck)
        dec4 = self.dec4(torch.cat([up4, enc4], dim=1))
        up3 = self.upconv3(dec4)
        dec3 = self.dec3(torch.cat([up3, enc3], dim=1))
        up2 = self.upconv2(dec3)
        dec2 = self.dec2(torch.cat([up2, enc2], dim=1))
        up1 = self.upconv1(dec2)
        dec1 = self.dec1(torch.cat([up1, enc1], dim=1))
        return self.final(dec1)

# Hybrid Retinex-U-Net Model
class HybridRetinexUNet(nn.Module):
    def _init_(self):
        super(HybridRetinexUNet, self)._init_()
        self.retinex = RetinexDecomposition()
        self.unet = UNetEnhancement()

    def forward(self, x):
        illumination, reflectance = self.retinex(x)
        enhanced_reflectance = self.unet(reflectance)
        if illumination.size() != enhanced_reflectance.size():
            illumination = F.interpolate(illumination, size=enhanced_reflectance.shape[2:], mode="bilinear",
                                         align_corners=False)
        enhanced_image = enhanced_reflectance * illumination
        return enhanced_image

# Dataset Class
class LowLightDataset(Dataset):
    def _init_(self, low_dir, high_dir, transform=None):
        self.low_dir = low_dir
        self.high_dir = high_dir
        self.transform = transform
        self.low_images = sorted(os.listdir(low_dir))
        self.high_images = sorted(os.listdir(high_dir))

    def _len_(self):
        return len(self.low_images)

    def _getitem_(self, idx):
        low_path = os.path.join(self.low_dir, self.low_images[idx])
        high_path = os.path.join(self.high_dir, self.high_images[idx])
        low_image = Image.open(low_path).convert("RGB")
        high_image = Image.open(high_path).convert("RGB")
        if self.transform:
            low_image = self.transform(low_image)
            high_image = self.transform(high_image)
        return low_image, high_image

# Metrics Calculation with Robust Win Size Handling
def calculate_metrics(predicted, ground_truth, low_light=None, show_images=False):
    predicted = predicted.squeeze().cpu().numpy().transpose(1, 2, 0)
    ground_truth = ground_truth.squeeze().cpu().numpy().transpose(1, 2, 0)

    if low_light is not None:
        low_light = low_light.squeeze().cpu().numpy().transpose(1, 2, 0)

    predicted = (predicted * 0.5 + 0.5).clip(0, 1)
    ground_truth = (ground_truth * 0.5 + 0.5).clip(0, 1)
    if low_light is not None:
        low_light = (low_light * 0.5 + 0.5).clip(0, 1)

    # Calculate metrics
    mse = ((predicted - ground_truth) ** 2).mean()
    mae = abs(predicted - ground_truth).mean()
    psnr_value = psnr(ground_truth, predicted, data_range=1)

    # Calculate MS-SSIM
    predicted_tensor = torch.tensor(predicted).permute(2, 0, 1).unsqueeze(0).to(device)
    ground_truth_tensor = torch.tensor(ground_truth).permute(2, 0, 1).unsqueeze(0).to(device)
    msssim_value = ms_ssim(predicted_tensor, ground_truth_tensor, data_range=1, size_average=True)

    # Visualization
    if show_images:
        fig, axes = plt.subplots(1, 3, figsize=(12, 4))
        axes[0].imshow(low_light)
        axes[0].set_title("Low-Light Input")
        axes[0].axis("off")
        axes[1].imshow(predicted)
        axes[1].set_title("Predicted Image")
        axes[1].axis("off")
        axes[2].imshow(ground_truth)
        axes[2].set_title("Ground Truth")
        axes[2].axis("off")
        plt.tight_layout()
        plt.show()

    return mse, mae, psnr_value, msssim_value.item()

# Training Function
def train_model(model, train_loader, test_loader, criterion, optimizer, device, num_epochs=50):
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for low, high in train_loader:
            low, high = low.to(device), high.to(device)
            optimizer.zero_grad()
            output = model(low)
            output_resized = F.interpolate(output, size=high.shape[2:], mode='bilinear', align_corners=False)
            loss = criterion(output_resized, high)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}")
        visualize = epoch % 5 == 0
        mse, mae, psnr_value, msssim_value = evaluate_model(model, test_loader, device, visualize=visualize)
        print(f"Test Metrics - MSE: {mse:.4f}, MAE: {mae:.4f}, PSNR: {psnr_value:.2f}, MS-SSIM: {msssim_value:.4f}")

# Evaluate Model
def evaluate_model(model, dataloader, device, visualize=False):
    model.eval()
    avg_mse, avg_mae, avg_psnr, avg_msssim = 0, 0, 0, 0
    with torch.no_grad():
        for low, high in dataloader:
            low, high = low.to(device), high.to(device)
            output = model(low)
            output_resized = F.interpolate(output, size=high.shape[2:], mode='bilinear', align_corners=False)
            for i in range(low.size(0)):
                mse, mae, psnr_value, msssim_value = calculate_metrics(
                    output_resized[i], high[i], low_light=low[i], show_images=visualize
                )
                avg_mse += mse
                avg_mae += mae
                avg_psnr += psnr_value
                avg_msssim += msssim_value

    num_samples = len(dataloader.dataset)
    return avg_mse / num_samples, avg_mae / num_samples, avg_psnr / num_samples, avg_msssim / num_samples

# Directories for Dataset
train_low_dir = '/content/drive/MyDrive/LOLdataset/lol_dataset/our485/low'
train_high_dir = '/content/drive/MyDrive/LOLdataset/lol_dataset/our485/high'
test_low_dir = '/content/drive/MyDrive/LOLdataset/lol_dataset/eval15/low'
test_high_dir = '/content/drive/MyDrive/LOLdataset/lol_dataset/eval15/high'

# Data Transformation and Loaders
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

train_dataset = LowLightDataset(train_low_dir, train_high_dir, transform)
test_dataset = LowLightDataset(test_low_dir, test_high_dir, transform)
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)

# Model, Loss, and Optimizer Setup
model = HybridRetinexUNet().to(device)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# Train the Model
train_model(model, train_loader, test_loader, criterion, optimizer, device,Â num_epochs=150)
